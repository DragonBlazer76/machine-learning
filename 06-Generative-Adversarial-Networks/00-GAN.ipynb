{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../03-Convolutional-Neural-Networks/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x125aad5c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12c4469e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[15].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Networks\n",
    "\n",
    "Useful Links:\n",
    "\n",
    "https://stackoverflow.com/questions/45307072/using-leaky-relu-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z is a random noise\n",
    "def generator(z,reuse=None):\n",
    "    with tf.variable_scope('gen',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=z,units=128)\n",
    "        # Leaky Relu\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        \n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        output = tf.layers.dense(hidden2,units=784,activation=tf.nn.tanh)\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(X,reuse=None):\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=X,units=128)\n",
    "        # Leaky Relu\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        \n",
    "        logits = tf.layers.dense(hidden2,units=1)\n",
    "        output = tf.sigmoid(logits)\n",
    "    \n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = tf.placeholder(tf.float32,shape=[None,784])\n",
    "z = tf.placeholder(tf.float32,shape=[None,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_output_real , D_logits_real = discriminator(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_output_fake, D_logits_fake = discriminator(G,reuse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(logits_in,labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_real_loss = loss_func(D_logits_real,tf.ones_like(D_logits_real)* (0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_fake_loss = loss_func(D_logits_fake,tf.zeros_like(D_logits_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = D_real_loss + D_fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dis/dense/kernel:0', 'dis/dense/bias:0', 'dis/dense_1/kernel:0', 'dis/dense_1/bias:0', 'dis/dense_2/kernel:0', 'dis/dense_2/bias:0']\n",
      "['gen/dense/kernel:0', 'gen/dense/bias:0', 'gen/dense_1/kernel:0', 'gen/dense_1/bias:0', 'gen/dense_2/kernel:0', 'gen/dense_2/bias:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss, var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 500\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a sample per epoch\n",
    "samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on Epoch 1 of 500 total...\n",
      "Currently on Epoch 2 of 500 total...\n",
      "Currently on Epoch 3 of 500 total...\n",
      "Currently on Epoch 4 of 500 total...\n",
      "Currently on Epoch 5 of 500 total...\n",
      "Currently on Epoch 6 of 500 total...\n",
      "Currently on Epoch 7 of 500 total...\n",
      "Currently on Epoch 8 of 500 total...\n",
      "Currently on Epoch 9 of 500 total...\n",
      "Currently on Epoch 10 of 500 total...\n",
      "Currently on Epoch 11 of 500 total...\n",
      "Currently on Epoch 12 of 500 total...\n",
      "Currently on Epoch 13 of 500 total...\n",
      "Currently on Epoch 14 of 500 total...\n",
      "Currently on Epoch 15 of 500 total...\n",
      "Currently on Epoch 16 of 500 total...\n",
      "Currently on Epoch 17 of 500 total...\n",
      "Currently on Epoch 18 of 500 total...\n",
      "Currently on Epoch 19 of 500 total...\n",
      "Currently on Epoch 20 of 500 total...\n",
      "Currently on Epoch 21 of 500 total...\n",
      "Currently on Epoch 22 of 500 total...\n",
      "Currently on Epoch 23 of 500 total...\n",
      "Currently on Epoch 24 of 500 total...\n",
      "Currently on Epoch 25 of 500 total...\n",
      "Currently on Epoch 26 of 500 total...\n",
      "Currently on Epoch 27 of 500 total...\n",
      "Currently on Epoch 28 of 500 total...\n",
      "Currently on Epoch 29 of 500 total...\n",
      "Currently on Epoch 30 of 500 total...\n",
      "Currently on Epoch 31 of 500 total...\n",
      "Currently on Epoch 32 of 500 total...\n",
      "Currently on Epoch 33 of 500 total...\n",
      "Currently on Epoch 34 of 500 total...\n",
      "Currently on Epoch 35 of 500 total...\n",
      "Currently on Epoch 36 of 500 total...\n",
      "Currently on Epoch 37 of 500 total...\n",
      "Currently on Epoch 38 of 500 total...\n",
      "Currently on Epoch 39 of 500 total...\n",
      "Currently on Epoch 40 of 500 total...\n",
      "Currently on Epoch 41 of 500 total...\n",
      "Currently on Epoch 42 of 500 total...\n",
      "Currently on Epoch 43 of 500 total...\n",
      "Currently on Epoch 44 of 500 total...\n",
      "Currently on Epoch 45 of 500 total...\n",
      "Currently on Epoch 46 of 500 total...\n",
      "Currently on Epoch 47 of 500 total...\n",
      "Currently on Epoch 48 of 500 total...\n",
      "Currently on Epoch 49 of 500 total...\n",
      "Currently on Epoch 50 of 500 total...\n",
      "Currently on Epoch 51 of 500 total...\n",
      "Currently on Epoch 52 of 500 total...\n",
      "Currently on Epoch 53 of 500 total...\n",
      "Currently on Epoch 54 of 500 total...\n",
      "Currently on Epoch 55 of 500 total...\n",
      "Currently on Epoch 56 of 500 total...\n",
      "Currently on Epoch 57 of 500 total...\n",
      "Currently on Epoch 58 of 500 total...\n",
      "Currently on Epoch 59 of 500 total...\n",
      "Currently on Epoch 60 of 500 total...\n",
      "Currently on Epoch 61 of 500 total...\n",
      "Currently on Epoch 62 of 500 total...\n",
      "Currently on Epoch 63 of 500 total...\n",
      "Currently on Epoch 64 of 500 total...\n",
      "Currently on Epoch 65 of 500 total...\n",
      "Currently on Epoch 66 of 500 total...\n",
      "Currently on Epoch 67 of 500 total...\n",
      "Currently on Epoch 68 of 500 total...\n",
      "Currently on Epoch 69 of 500 total...\n",
      "Currently on Epoch 70 of 500 total...\n",
      "Currently on Epoch 71 of 500 total...\n",
      "Currently on Epoch 72 of 500 total...\n",
      "Currently on Epoch 73 of 500 total...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-79c42d3c4730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Run optimizers, no need to save outputs, we won't use them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_trainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mreal_images\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_z\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_trainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_z\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tfdeeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tfdeeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tfdeeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tfdeeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tfdeeplearning/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    # Recall an epoch is an entire run through the training data\n",
    "    for e in range(epochs):\n",
    "        # // indicates classic division\n",
    "        num_batches = mnist.train.num_examples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            # Grab batch of images\n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Get images, reshape and rescale to pass to D\n",
    "            batch_images = batch[0].reshape((batch_size, 784))\n",
    "            batch_images = batch_images*2 - 1\n",
    "            \n",
    "            # Z (random latent noise data for Generator)\n",
    "            # -1 to 1 because of tanh activation\n",
    "            batch_z = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "            \n",
    "            # Run optimizers, no need to save outputs, we won't use them\n",
    "            _ = sess.run(D_trainer, feed_dict={real_images: batch_images, z: batch_z})\n",
    "            _ = sess.run(G_trainer, feed_dict={z: batch_z})\n",
    "        \n",
    "            \n",
    "        print(\"Currently on Epoch {} of {} total...\".format(e+1, epochs))\n",
    "        \n",
    "        # Sample from generator as we're training for viewing afterwards\n",
    "        sample_z = np.random.uniform(-1, 1, size=(1, 100))\n",
    "        gen_sample = sess.run(generator(z ,reuse=True),feed_dict={z: sample_z})\n",
    "        \n",
    "        samples.append(gen_sample)\n",
    "        \n",
    "#         saver.save(sess, './models/500_epoch_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./models/500_epoch_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "\n",
    "new_samples = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,'./models/500_epoch_model.ckpt')\n",
    "    \n",
    "    for x in range(5):\n",
    "        sample_z = np.random.uniform(-1,1,size=(1,100))\n",
    "        gen_sample = sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
    "        \n",
    "        new_samples.append(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1252c1c88>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12515bdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(new_samples[3].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
