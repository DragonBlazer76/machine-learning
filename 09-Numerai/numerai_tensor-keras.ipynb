{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('../../numerai_datasets/numerai_training_data.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = pd.read_csv('../../numerai_datasets/numerai_tournament_data.csv',  header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature1 = tf.feature_column.numeric_column('feature1')\n",
    "#feature2 = tf.feature_column.numeric_column('feature2')\n",
    "#feature3 = tf.feature_column.numeric_column('feature3')\n",
    "#feature4 = tf.feature_column.numeric_column('feature4')\n",
    "#feature5 = tf.feature_column.numeric_column('feature5')\n",
    "#feature6 = tf.feature_column.numeric_column('feature6')\n",
    "#feature7 = tf.feature_column.numeric_column('feature7')\n",
    "feature8 = tf.feature_column.numeric_column('feature8')\n",
    "feature9 = tf.feature_column.numeric_column('feature9')\n",
    "#feature10 = tf.feature_column.numeric_column('feature10')\n",
    "feature11 = tf.feature_column.numeric_column('feature11')\n",
    "#feature12 = tf.feature_column.numeric_column('feature12')\n",
    "feature13 = tf.feature_column.numeric_column('feature13')\n",
    "#feature14 = tf.feature_column.numeric_column('feature14')\n",
    "#feature15 = tf.feature_column.numeric_column('feature15')\n",
    "feature16 = tf.feature_column.numeric_column('feature16')\n",
    "#feature17 = tf.feature_column.numeric_column('feature17')\n",
    "#feature18 = tf.feature_column.numeric_column('feature18')\n",
    "#feature19 = tf.feature_column.numeric_column('feature19')\n",
    "#feature20 = tf.feature_column.numeric_column('feature20')\n",
    "#feature21 = tf.feature_column.numeric_column('feature21')\n",
    "#feature22 = tf.feature_column.numeric_column('feature22')\n",
    "#feature23 = tf.feature_column.numeric_column('feature23')\n",
    "feature24 = tf.feature_column.numeric_column('feature24')\n",
    "#feature25 = tf.feature_column.numeric_column('feature25')\n",
    "#feature26 = tf.feature_column.numeric_column('feature26')\n",
    "feature27 = tf.feature_column.numeric_column('feature27')\n",
    "feature28 = tf.feature_column.numeric_column('feature28')\n",
    "#feature29 = tf.feature_column.numeric_column('feature29')\n",
    "#feature30 = tf.feature_column.numeric_column('feature30')\n",
    "feature31 = tf.feature_column.numeric_column('feature31')\n",
    "#feature32 = tf.feature_column.numeric_column('feature32')\n",
    "#feature33 = tf.feature_column.numeric_column('feature33')\n",
    "#feature34 = tf.feature_column.numeric_column('feature34')\n",
    "#feature35 = tf.feature_column.numeric_column('feature35')\n",
    "feature36 = tf.feature_column.numeric_column('feature36')\n",
    "feature37 = tf.feature_column.numeric_column('feature37')\n",
    "#feature38 = tf.feature_column.numeric_column('feature38')\n",
    "#feature39 = tf.feature_column.numeric_column('feature39')\n",
    "#feature40 = tf.feature_column.numeric_column('feature40')\n",
    "#feature41 = tf.feature_column.numeric_column('feature41')\n",
    "#feature42 = tf.feature_column.numeric_column('feature42')\n",
    "#feature43 = tf.feature_column.numeric_column('feature43')\n",
    "#feature44 = tf.feature_column.numeric_column('feature44')\n",
    "#feature45 = tf.feature_column.numeric_column('feature45')\n",
    "feature46 = tf.feature_column.numeric_column('feature46')\n",
    "feature47 = tf.feature_column.numeric_column('feature47')\n",
    "#feature48 = tf.feature_column.numeric_column('feature48')\n",
    "#feature49 = tf.feature_column.numeric_column('feature49')\n",
    "#feature50 = tf.feature_column.numeric_column('feature50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [\n",
    "    feature8, feature9, feature11, feature13, feature16, feature24, feature27, \n",
    "    feature28, feature31, feature36, feature37, feature46, feature47\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_data = training_data.drop(['id', 'era', 'data_type','target'], axis=1)\n",
    "x_data = training_data[[\n",
    "    'feature8', 'feature9', 'feature11', 'feature13', 'feature16', 'feature24', 'feature27', 'feature28', \n",
    "    'feature31', 'feature36', 'feature37', 'feature46', 'feature47'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = training_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,labels,test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_keras_model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_keras_model.add(layers.Dense(units=X_train.shape[1],input_dim=13,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_keras_model.add(layers.Dense(units=10,activation='relu', kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001), activity_regularizer=tf.contrib.layers.l1_regularizer(0.01)))\n",
    "dnn_keras_model.add(layers.Dropout(0.8))\n",
    "#dnn_keras_model.add(layers.Dense(units=7,activation='relu', kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001), activity_regularizer=tf.contrib.layers.l1_regularizer(0.01)))\n",
    "#dnn_keras_model.add(layers.Dropout(0.1))\n",
    "#dnn_keras_model.add(layers.Dense(units=10,activation='relu', kernel_regularizer=tf.contrib.layers.l2_regularizer(0.001), activity_regularizer=tf.contrib.layers.l1_regularizer(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_keras_model.add(layers.Dense(units=2,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import losses,optimizers,metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#losses.sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_keras_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_keras_model.fit(X_train,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = dnn_keras_model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(predictions,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1_data = prediction_data.drop(['id', 'era', 'data_type','target'], axis=1)\n",
    "x1_data = prediction_data[[    'feature8', 'feature9', 'feature11', 'feature13', 'feature16', 'feature24', 'feature27', 'feature28', \n",
    "    'feature31', 'feature36', 'feature37', 'feature46', 'feature47'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = prediction_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(x1_data,labels1,test_size=1, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = dnn_keras_model.predict_proba(x1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for x in range(len(prob)):\n",
    "    results.append(prob[x][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = prediction_data[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df = results_df.rename(index=str, columns = {'0':'probabilities'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.DataFrame(ids).join(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = joined.rename(index=str, columns={'id':'id', 0:\"probability\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.to_csv(\"predictions1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfdeeplearning]",
   "language": "python",
   "name": "conda-env-tfdeeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
