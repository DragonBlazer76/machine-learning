{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('../../numerai_datasets/numerai_training_data.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = pd.read_csv('../../numerai_datasets/numerai_tournament_data.csv',  header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature1 = tf.feature_column.numeric_column('feature1')\n",
    "#feature2 = tf.feature_column.numeric_column('feature2')\n",
    "#feature3 = tf.feature_column.numeric_column('feature3')\n",
    "#feature4 = tf.feature_column.numeric_column('feature4')\n",
    "feature5 = tf.feature_column.numeric_column('feature5')\n",
    "feature6 = tf.feature_column.numeric_column('feature6')\n",
    "#feature7 = tf.feature_column.numeric_column('feature7')\n",
    "#feature8 = tf.feature_column.numeric_column('feature8')\n",
    "#feature9 = tf.feature_column.numeric_column('feature9')\n",
    "#feature10 = tf.feature_column.numeric_column('feature10')\n",
    "#feature11 = tf.feature_column.numeric_column('feature11')\n",
    "#feature12 = tf.feature_column.numeric_column('feature12')\n",
    "#feature13 = tf.feature_column.numeric_column('feature13')\n",
    "feature14 = tf.feature_column.numeric_column('feature14')\n",
    "#feature15 = tf.feature_column.numeric_column('feature15')\n",
    "feature16 = tf.feature_column.numeric_column('feature16')\n",
    "#feature17 = tf.feature_column.numeric_column('feature17')\n",
    "#feature18 = tf.feature_column.numeric_column('feature18')\n",
    "#feature19 = tf.feature_column.numeric_column('feature19')\n",
    "feature20 = tf.feature_column.numeric_column('feature20')\n",
    "#feature21 = tf.feature_column.numeric_column('feature21')\n",
    "#feature22 = tf.feature_column.numeric_column('feature22')\n",
    "#feature23 = tf.feature_column.numeric_column('feature23')\n",
    "feature24 = tf.feature_column.numeric_column('feature24')\n",
    "#feature25 = tf.feature_column.numeric_column('feature25')\n",
    "#feature26 = tf.feature_column.numeric_column('feature26')\n",
    "feature27 = tf.feature_column.numeric_column('feature27')\n",
    "#feature28 = tf.feature_column.numeric_column('feature28')\n",
    "#feature29 = tf.feature_column.numeric_column('feature29')\n",
    "feature30 = tf.feature_column.numeric_column('feature30')\n",
    "#feature31 = tf.feature_column.numeric_column('feature31')\n",
    "#feature32 = tf.feature_column.numeric_column('feature32')\n",
    "feature33 = tf.feature_column.numeric_column('feature33')\n",
    "#feature34 = tf.feature_column.numeric_column('feature34')\n",
    "#feature35 = tf.feature_column.numeric_column('feature35')\n",
    "#feature36 = tf.feature_column.numeric_column('feature36')\n",
    "#feature37 = tf.feature_column.numeric_column('feature37')\n",
    "#feature38 = tf.feature_column.numeric_column('feature38')\n",
    "#feature39 = tf.feature_column.numeric_column('feature39')\n",
    "#feature40 = tf.feature_column.numeric_column('feature40')\n",
    "feature41 = tf.feature_column.numeric_column('feature41')\n",
    "#feature42 = tf.feature_column.numeric_column('feature42')\n",
    "#feature43 = tf.feature_column.numeric_column('feature43')\n",
    "#feature44 = tf.feature_column.numeric_column('feature44')\n",
    "feature45 = tf.feature_column.numeric_column('feature45')\n",
    "#feature46 = tf.feature_column.numeric_column('feature46')\n",
    "#feature47 = tf.feature_column.numeric_column('feature47')\n",
    "#feature48 = tf.feature_column.numeric_column('feature48')\n",
    "#feature49 = tf.feature_column.numeric_column('feature49')\n",
    "#feature50 = tf.feature_column.numeric_column('feature50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [\n",
    "       feature5, feature6,\n",
    "       feature14, feature16, feature20,\n",
    "       feature24, feature27, feature30, feature33,\n",
    "       feature41, feature45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = training_data[['feature5', 'feature6',\n",
    "       'feature14', 'feature16', 'feature20',\n",
    "       'feature24', 'feature27', 'feature30', 'feature33', \n",
    "       'feature41', 'feature45']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = training_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_norm = ['feature1', 'feature2', 'feature3',\n",
    "       'feature4', 'feature5', 'feature6', 'feature7', 'feature8', 'feature9',\n",
    "       'feature10', 'feature11', 'feature12', 'feature13', 'feature14',\n",
    "       'feature15', 'feature16', 'feature17', 'feature18', 'feature19',\n",
    "       'feature20', 'feature21', 'feature22', 'feature23', 'feature24',\n",
    "       'feature25', 'feature26', 'feature27', 'feature28', 'feature29',\n",
    "       'feature30', 'feature31', 'feature32', 'feature33', 'feature34',\n",
    "       'feature35', 'feature36', 'feature37', 'feature38', 'feature39',\n",
    "       'feature40', 'feature41', 'feature42', 'feature43', 'feature44',\n",
    "       'feature45', 'feature46', 'feature47', 'feature48', 'feature49',\n",
    "       'feature50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##x_data[col_to_norm] = x_data[col_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,labels,test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=10,num_epochs=None,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/_6/y3kprftx5gz9pzhx9yk35dmc0000gn/T/tmp4i8nmzhx\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/_6/y3kprftx5gz9pzhx9yk35dmc0000gn/T/tmp4i8nmzhx', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10bd4b978>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.estimator.DNNClassifier(hidden_units=[256, 256, 256],feature_columns=feat_cols,n_classes=2,optimizer=tf.train.AdamOptimizer(learning_rate=0.003), activation_fn=tf.nn.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/_6/y3kprftx5gz9pzhx9yk35dmc0000gn/T/tmp4i8nmzhx/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.934658, step = 1\n",
      "INFO:tensorflow:global_step/sec: 394.28\n",
      "INFO:tensorflow:loss = 7.023137, step = 101 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 488.508\n",
      "INFO:tensorflow:loss = 6.9551215, step = 201 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.251\n",
      "INFO:tensorflow:loss = 6.9310813, step = 301 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.258\n",
      "INFO:tensorflow:loss = 6.907159, step = 401 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 450.507\n",
      "INFO:tensorflow:loss = 7.204512, step = 501 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.799\n",
      "INFO:tensorflow:loss = 6.931711, step = 601 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 482.276\n",
      "INFO:tensorflow:loss = 6.9387145, step = 701 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.605\n",
      "INFO:tensorflow:loss = 7.0021515, step = 801 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.557\n",
      "INFO:tensorflow:loss = 6.9720006, step = 901 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.4\n",
      "INFO:tensorflow:loss = 6.8680487, step = 1001 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 444.466\n",
      "INFO:tensorflow:loss = 6.93155, step = 1101 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.241\n",
      "INFO:tensorflow:loss = 6.931739, step = 1201 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.569\n",
      "INFO:tensorflow:loss = 6.933602, step = 1301 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.886\n",
      "INFO:tensorflow:loss = 6.9093637, step = 1401 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.25\n",
      "INFO:tensorflow:loss = 6.966349, step = 1501 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.341\n",
      "INFO:tensorflow:loss = 6.908496, step = 1601 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.473\n",
      "INFO:tensorflow:loss = 6.9226813, step = 1701 (0.207 sec)\n",
      "INFO:tensorflow:global_step/sec: 493.528\n",
      "INFO:tensorflow:loss = 6.931916, step = 1801 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.362\n",
      "INFO:tensorflow:loss = 6.9318304, step = 1901 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.976\n",
      "INFO:tensorflow:loss = 6.8829365, step = 2001 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.344\n",
      "INFO:tensorflow:loss = 6.976285, step = 2101 (0.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.153\n",
      "INFO:tensorflow:loss = 6.8440943, step = 2201 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.145\n",
      "INFO:tensorflow:loss = 6.931617, step = 2301 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 449.958\n",
      "INFO:tensorflow:loss = 6.875059, step = 2401 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.262\n",
      "INFO:tensorflow:loss = 6.9567127, step = 2501 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.261\n",
      "INFO:tensorflow:loss = 6.9490457, step = 2601 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 484.261\n",
      "INFO:tensorflow:loss = 6.961795, step = 2701 (0.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.81\n",
      "INFO:tensorflow:loss = 6.9422045, step = 2801 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.987\n",
      "INFO:tensorflow:loss = 6.9314775, step = 2901 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.678\n",
      "INFO:tensorflow:loss = 6.9543185, step = 3001 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.069\n",
      "INFO:tensorflow:loss = 6.8663774, step = 3101 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 486.911\n",
      "INFO:tensorflow:loss = 6.9249225, step = 3201 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 487.572\n",
      "INFO:tensorflow:loss = 6.953674, step = 3301 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 496.298\n",
      "INFO:tensorflow:loss = 6.931649, step = 3401 (0.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.404\n",
      "INFO:tensorflow:loss = 6.9314785, step = 3501 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 491.422\n",
      "INFO:tensorflow:loss = 6.9713993, step = 3601 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 490.682\n",
      "INFO:tensorflow:loss = 6.9333315, step = 3701 (0.204 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.343\n",
      "INFO:tensorflow:loss = 6.9283953, step = 3801 (0.209 sec)\n",
      "INFO:tensorflow:global_step/sec: 480.502\n",
      "INFO:tensorflow:loss = 6.931472, step = 3901 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.827\n",
      "INFO:tensorflow:loss = 6.921876, step = 4001 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 492.235\n",
      "INFO:tensorflow:loss = 6.891474, step = 4101 (0.203 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.373\n",
      "INFO:tensorflow:loss = 6.8982286, step = 4201 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 453.552\n",
      "INFO:tensorflow:loss = 6.9323006, step = 4301 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.732\n",
      "INFO:tensorflow:loss = 6.912777, step = 4401 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 479.849\n",
      "INFO:tensorflow:loss = 6.9660416, step = 4501 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.679\n",
      "INFO:tensorflow:loss = 6.9349957, step = 4601 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.389\n",
      "INFO:tensorflow:loss = 6.948929, step = 4701 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.164\n",
      "INFO:tensorflow:loss = 6.9320464, step = 4801 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.747\n",
      "INFO:tensorflow:loss = 6.8860893, step = 4901 (0.219 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/_6/y3kprftx5gz9pzhx9yk35dmc0000gn/T/tmp4i8nmzhx/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 7.0322685.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x111067d30>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.train(input_fn=input_func,steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      y=y_test,\n",
    "      batch_size=len(X_test),\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-05-02:39:09\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/_6/y3kprftx5gz9pzhx9yk35dmc0000gn/T/tmp4i8nmzhx/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-05-02:39:12\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.4986789, accuracy_baseline = 0.5013211, auc = 0.5, auc_precision_recall = 0.75066054, average_loss = 0.6942802, global_step = 5000, label/mean = 0.5013211, loss = 81983.38, prediction/mean = 0.47760555\n"
     ]
    }
   ],
   "source": [
    "results = dnn_model.evaluate(eval_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.4986789,\n",
       " 'accuracy_baseline': 0.5013211,\n",
       " 'auc': 0.5,\n",
       " 'auc_precision_recall': 0.75066054,\n",
       " 'average_loss': 0.6942802,\n",
       " 'global_step': 5000,\n",
       " 'label/mean': 0.5013211,\n",
       " 'loss': 81983.38,\n",
       " 'prediction/mean': 0.47760555}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = prediction_data.drop(['id', 'era', 'data_type','target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = prediction_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(x1_data,labels1,test_size=1, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=x1_data,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions is a generator! \n",
    "predictions = dnn_model.predict(pred_input_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for x in dnn_model.predict(pred_input_func):\n",
    "        results.append(x['probabilities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "results = np.delete(results,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = prediction_data[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df = results_df.rename(index=str, columns = {'0':'probabilities'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.DataFrame(ids).join(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfdeeplearning]",
   "language": "python",
   "name": "conda-env-tfdeeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
