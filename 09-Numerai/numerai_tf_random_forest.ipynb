{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "from tensorflow.python.ops import resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('../../numerai_datasets/numerai_training_data.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = pd.read_csv('../../numerai_datasets/numerai_tournament_data.csv',  header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature1 = tf.feature_column.numeric_column('feature1')\n",
    "#feature2 = tf.feature_column.numeric_column('feature2')\n",
    "#feature3 = tf.feature_column.numeric_column('feature3')\n",
    "#feature4 = tf.feature_column.numeric_column('feature4')\n",
    "#feature5 = tf.feature_column.numeric_column('feature5')\n",
    "#feature6 = tf.feature_column.numeric_column('feature6')\n",
    "#feature7 = tf.feature_column.numeric_column('feature7')\n",
    "feature8 = tf.feature_column.numeric_column('feature8')\n",
    "feature9 = tf.feature_column.numeric_column('feature9')\n",
    "#feature10 = tf.feature_column.numeric_column('feature10')\n",
    "feature11 = tf.feature_column.numeric_column('feature11')\n",
    "#feature12 = tf.feature_column.numeric_column('feature12')\n",
    "feature13 = tf.feature_column.numeric_column('feature13')\n",
    "#feature14 = tf.feature_column.numeric_column('feature14')\n",
    "#feature15 = tf.feature_column.numeric_column('feature15')\n",
    "feature16 = tf.feature_column.numeric_column('feature16')\n",
    "#feature17 = tf.feature_column.numeric_column('feature17')\n",
    "#feature18 = tf.feature_column.numeric_column('feature18')\n",
    "#feature19 = tf.feature_column.numeric_column('feature19')\n",
    "#feature20 = tf.feature_column.numeric_column('feature20')\n",
    "#feature21 = tf.feature_column.numeric_column('feature21')\n",
    "#feature22 = tf.feature_column.numeric_column('feature22')\n",
    "#feature23 = tf.feature_column.numeric_column('feature23')\n",
    "feature24 = tf.feature_column.numeric_column('feature24')\n",
    "#feature25 = tf.feature_column.numeric_column('feature25')\n",
    "#feature26 = tf.feature_column.numeric_column('feature26')\n",
    "feature27 = tf.feature_column.numeric_column('feature27')\n",
    "feature28 = tf.feature_column.numeric_column('feature28')\n",
    "#feature29 = tf.feature_column.numeric_column('feature29')\n",
    "#feature30 = tf.feature_column.numeric_column('feature30')\n",
    "feature31 = tf.feature_column.numeric_column('feature31')\n",
    "#feature32 = tf.feature_column.numeric_column('feature32')\n",
    "#feature33 = tf.feature_column.numeric_column('feature33')\n",
    "#feature34 = tf.feature_column.numeric_column('feature34')\n",
    "#feature35 = tf.feature_column.numeric_column('feature35')\n",
    "feature36 = tf.feature_column.numeric_column('feature36')\n",
    "feature37 = tf.feature_column.numeric_column('feature37')\n",
    "#feature38 = tf.feature_column.numeric_column('feature38')\n",
    "#feature39 = tf.feature_column.numeric_column('feature39')\n",
    "#feature40 = tf.feature_column.numeric_column('feature40')\n",
    "#feature41 = tf.feature_column.numeric_column('feature41')\n",
    "#feature42 = tf.feature_column.numeric_column('feature42')\n",
    "#feature43 = tf.feature_column.numeric_column('feature43')\n",
    "#feature44 = tf.feature_column.numeric_column('feature44')\n",
    "#feature45 = tf.feature_column.numeric_column('feature45')\n",
    "feature46 = tf.feature_column.numeric_column('feature46')\n",
    "feature47 = tf.feature_column.numeric_column('feature47')\n",
    "#feature48 = tf.feature_column.numeric_column('feature48')\n",
    "#feature49 = tf.feature_column.numeric_column('feature49')\n",
    "#feature50 = tf.feature_column.numeric_column('feature50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [\n",
    "    feature8, feature9, feature11, feature13, feature16, feature24, feature27, \n",
    "    feature28, feature31, feature36, feature37, feature46, feature47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = training_data[[\n",
    "    'feature8', 'feature9', 'feature11', 'feature13', 'feature16', 'feature24', 'feature27', 'feature28', \n",
    "    'feature31', 'feature36', 'feature37', 'feature46', 'feature47']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = training_data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data,labels,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_steps = 500 # Total steps to train\n",
    "batch_size = 1024 # The number of samples per batch\n",
    "num_classes = 2 # The 10 digits\n",
    "num_features = 13 # 50 columns\n",
    "num_trees = 10\n",
    "max_nodes = 1000\n",
    "display_step = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(\"float32\", shape=[None, num_features])\n",
    "y = tf.placeholder(\"float32\", shape=[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Parameters\n",
    "hparams = tensor_forest.ForestHParams(num_classes=num_classes,\n",
    "                                      num_features=num_features,\n",
    "                                      num_trees=num_trees,\n",
    "                                      max_nodes=max_nodes).fill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Random Forest\n",
    "forest_graph = tensor_forest.RandomForestGraphs(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training graph and loss\n",
    "train_op = forest_graph.training_graph(x, y)\n",
    "loss_op = forest_graph.training_loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the variables (i.e. assign their default value) and forest resources\n",
    "init_vars = tf.group(tf.global_variables_initializer(),\n",
    "    resources.initialize_resources(resources.shared_resources()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the accuracy\n",
    "infer_op, _, _ = forest_graph.inference_graph(x)\n",
    "correct_prediction = tf.equal(tf.argmax(infer_op, 1), tf.cast(y, tf.int64))\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start TensorFlow session\n",
    "#sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the initializer\n",
    "#sess.run(init_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([y_train, -(y_train-1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([y_test, -(y_test-1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    sess.run(init_vars)\n",
    "    # Training cycle\n",
    "    for epoch in range(num_steps):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(len(X_train)/batch_size)\n",
    "        X_batches = np.array_split(X_train, total_batch)\n",
    "        Y_batches = np.array_split(y_train, total_batch)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = X_batches[i], Y_batches[i]\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([train_op, loss_op], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            if i % 50 == 0 or i == 1:\n",
    "                acc = sess.run(accuracy_op, feed_dict={x: batch_x, y: batch_y})\n",
    "                print('Step %i, Loss: %f, Acc: %f' % (i, c, acc))\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "            \n",
    "\n",
    "        \n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "for i in range(1, num_steps + 1):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    avg_cost = 0.\n",
    "    total_batch = int(len(X_train)/batch_size)\n",
    "    X_batches = np.array_split(X_train, total_batch)\n",
    "    Y_batches = np.array_split(y_train, total_batch)\n",
    "    # Loop over all batches\n",
    "    for j in range(total_batch):\n",
    "        batch_x, batch_y = X_batches[j], Y_batches[j]\n",
    "        print(batch_x)\n",
    "        _, l = sess.run([train_op, loss_op], feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        # Compute average loss\n",
    "        avg_cost += l / total_batch\n",
    "    # Display logs per epoch step\n",
    "    if i % display_step == 0:\n",
    "        print('1. Step %i, Loss: %f' % (i, l))\n",
    "   \n",
    "    #if i % 50 == 0 or i == 1:\n",
    "    #    acc = sess.run(accuracy_op, feed_dict={x: batch_x, y: batch_y})\n",
    "    #    print('Step %i, Loss: %f, Acc: %f' % (i, l, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tfdeeplearning]",
   "language": "python",
   "name": "conda-env-tfdeeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
